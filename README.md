# Extractor de Datos JSON desde CSV de Logs y Elasticsearch

Herramienta Python para extraer y procesar datos JSON embebidos en archivos CSV de logs o directamente desde Elasticsearch/Kibana. Filtra automÃ¡ticamente valores no nulos, elimina duplicados y exporta los resultados a JSON limpio.

## ğŸš€ CaracterÃ­sticas

- âœ… **MÃºltiples fuentes de datos** - CSV local o Elasticsearch/Kibana API
- âœ… **ExtracciÃ³n automÃ¡tica** de datos JSON desde columnas de mensajes
- ğŸ” **Filtrado inteligente** - solo valores diferentes de `null`
- ğŸ¯ **EliminaciÃ³n de duplicados** - resultados Ãºnicos basados en campo + valor
- ğŸ“Š **Progreso en tiempo real** - visualizaciÃ³n del procesamiento cada 1000 registros
- ğŸ›¡ï¸ **Manejo robusto de errores** - continÃºa procesando aunque algÃºn registro falle
- âš™ï¸ **ConfiguraciÃ³n flexible** - queries personalizables de Elasticsearch
- ğŸ“ **EstadÃ­sticas detalladas** - resumen completo al finalizar
- ğŸ”’ **Seguro** - credenciales en archivo `.env` no commiteado
- ğŸŒ **Interfaz web** - GUI moderna para visualizar y configurar conexiones

## ğŸ“‹ Requisitos

- Python 3.6 o superior
- LibrerÃ­as:
  - `elasticsearch>=8.11.0` (para conexiÃ³n a Elasticsearch/Kibana)
  - `python-dotenv>=1.0.0` (para gestiÃ³n de variables de entorno)

## ğŸ”§ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/extractor-csv-json.git
cd extractor-csv-json

# Instalar dependencias
pip install -r requirements.txt

# Configurar credenciales (solo si usarÃ¡s Elasticsearch)
cp .env.example .env
# Edita .env con tus credenciales reales
```

## ğŸ’» Uso

### ğŸŒ OpciÃ³n recomendada: Interfaz Web (con GUI)

La forma mÃ¡s fÃ¡cil y visual de usar la aplicaciÃ³n:

```bash
# Windows
start_web.bat

# Linux/Mac
bash start_web.sh

# O manualmente
python app_web.py
```

Accede a **http://localhost:5000** en tu navegador.

**CaracterÃ­sticas:**
- âœ… Login visual con credenciales
- âœ… Explorador de Ã­ndices interactivo
- âœ… Editor de queries con sintaxis JSON
- âœ… Visor de resultados con formato
- âœ… ExportaciÃ³n a JSON
- âœ… Interfaz responsive (mobile-friendly)

[ğŸ“– Ver documentaciÃ³n completa de la interfaz web](WEB_README.md)

---

### OpciÃ³n 1: Procesar CSV local

#### MÃ©todo directo (script original)

1. Edita las rutas en `extractor_csv.py` (lÃ­neas 16-17):

```python
INPUT_CSV = "tu_archivo.csv"
OUTPUT_JSON = "salida.json"
```

2. Ejecuta el script:

```bash
python extractor_csv.py
```

#### MÃ©todo CLI (recomendado)

```bash
python main.py csv --input archivo.csv --output salida.json
```

### OpciÃ³n 2: Descargar desde Elasticsearch/Kibana

#### ConfiguraciÃ³n inicial

1. Copia el archivo de ejemplo de configuraciÃ³n:
```bash
cp .env.example .env
```

2. Edita `.env` con tus credenciales:
```env
ELASTICSEARCH_HOST=https://elk.unir.net
ELASTICSEARCH_USER=tu_usuario
ELASTICSEARCH_PASSWORD=tu_contraseÃ±a
ELASTICSEARCH_INDEX=logs-*
```

3. Prueba la conexiÃ³n:
```bash
python main.py test-connection
```

#### Descarga y procesamiento

**Directo a JSON (mÃ¡s eficiente):**
```bash
python main.py elasticsearch --output-json datos.json
```

**Con CSV intermedio (para auditorÃ­a):**
```bash
python main.py elasticsearch --output-csv logs.csv --output-json datos.json
```

**Con query personalizada:**
```bash
python main.py elasticsearch --query-file queries/error_logs_ejemplo.json --output-json datos.json
```

**Con Ã­ndice especÃ­fico:**
```bash
python main.py elasticsearch --index "logs-2026.02.*" --output-json datos.json
```

**Modo verbose (ver query y detalles):**
```bash
python main.py elasticsearch --output-json datos.json --verbose
```

### OpciÃ³n 3: Uso como mÃ³dulo

```python
# Desde CSV
from extractor_csv import procesar_csv
stats = procesar_csv("entrada.csv", "salida.json")

# Desde Elasticsearch
from config import load_config
from elasticsearch_client import ElasticsearchClient
from data_processor import procesar_registros_iterable

config = load_config()
client = ElasticsearchClient(config)

query = {"query": {"match_all": {}}}
docs = client.get_documents_generator(query)
stats = procesar_registros_iterable(docs, "salida.json")
```

## ğŸ“Š Formato de datos

### Entrada esperada (CSV)

El script espera un archivo CSV con una columna llamada `message` que contenga JSON con esta estructura:

```
Body: {"where":[{"field":"idAsignaturaOfertada","value":294859},{"field":"idAsignaturaPlan","value":null},{"field":"idEstudio","value":null},{"field":"idPlanEstudio","value":5109}]}
```

### Salida generada (JSON)

```json
[
  {
    "field": "idAsignaturaOfertada",
    "value": 294859
  },
  {
    "field": "idPlanEstudio",
    "value": 5109
  }
]
```

**Nota:** Solo se incluyen campos con valores diferentes de `null` y se eliminan duplicados.

## ğŸ“– Ejemplo de ejecuciÃ³n

### Desde CSV local

```
============================================================
  PROCESADOR DE CSV LOCAL
============================================================

ğŸ“‚ Procesando archivo: Error Evaluacion Niveles Escala.csv
â³ Procesando registros...
  âœ“ Procesados 1,000 registros...
  âœ“ Procesados 2,000 registros...
  âœ“ Procesados 3,000 registros...
  âœ“ Procesados 4,000 registros...
âœ“ Total de registros procesados: 4,524
ğŸ“Š Registros con valores: 498
ğŸ“Š Valores Ãºnicos encontrados: 17
ğŸ’¾ Archivo generado: datos_extraidos.json

============================================================
  âœ… PROCESO COMPLETADO EXITOSAMENTE
============================================================
  ğŸ“‹ Registros procesados: 4,524
  ğŸ“Š Valores Ãºnicos extraÃ­dos: 17
  ğŸ“ Archivo de salida: datos_extraidos.json
============================================================
```

### Desde Elasticsearch

```
============================================================
  EXTRACTOR DESDE ELASTICSEARCH
============================================================

âš™ï¸  Cargando configuraciÃ³n...
âœ“ ConfiguraciÃ³n cargada: https://elk.unir.net
ğŸ”Œ Conectando a Elasticsearch...
âœ… Conectado a: production-cluster (v8.11.0)
ğŸ“Š Ãndice: logs-*
ğŸ“Š Documentos estimados: 15,234

ğŸ“¥ Descargando y procesando directamente a JSON...
â³ Procesando registros...
  âœ“ Procesados 1,000 registros...
  âœ“ Procesados 2,000 registros...
  ...
âœ“ Total de registros procesados: 15,234
ğŸ“Š Registros con valores: 892
ğŸ“Š Valores Ãºnicos encontrados: 45
ğŸ’¾ Archivo generado: datos_extraidos.json

============================================================
  âœ… PROCESO COMPLETADO EXITOSAMENTE
============================================================
  ğŸ“‹ Registros procesados: 15,234
  ğŸ“Š Registros con valores: 892
  ğŸ“Š Valores Ãºnicos extraÃ­dos: 45
  ğŸ“ Archivo de salida JSON: datos_extraidos.json
============================================================
```

## ğŸ” Funciones principales

### MÃ³dulo `data_processor.py`
- **`normalizar_json(text)`** - Extrae JSON del campo Body del mensaje
- **`extraer_valores_no_nulos(json_data)`** - Filtra valores diferentes de null
- **`procesar_mensaje(message)`** - Procesa mensaje completo
- **`procesar_registros_iterable(registros, output)`** - Procesa cualquier fuente de datos

### MÃ³dulo `elasticsearch_client.py`
- **`ElasticsearchClient(config)`** - Cliente para conectar a Elasticsearch
- **`test_connection()`** - Verifica conectividad
- **`search_logs(query, index)`** - Busca logs con Scroll API
- **`download_to_csv(query, output)`** - Descarga resultados a CSV
- **`get_documents_generator(query)`** - Generador para procesamiento directo

### MÃ³dulo `config.py`
- **`load_config()`** - Carga y valida configuraciÃ³n desde .env
- **`Config`** - Clase con toda la configuraciÃ³n de la aplicaciÃ³n

## âš™ï¸ ConfiguraciÃ³n avanzada

### Variables de entorno (.env)

```env
# Requeridas
ELASTICSEARCH_HOST=https://elk.unir.net
ELASTICSEARCH_USER=tu_usuario
ELASTICSEARCH_PASSWORD=tu_contraseÃ±a
ELASTICSEARCH_INDEX=logs-*

# Opcionales
ELASTICSEARCH_VERIFY_SSL=true         # Verificar certificados SSL
ELASTICSEARCH_TIMEOUT=300             # Timeout en segundos
ELASTICSEARCH_SCROLL_SIZE=1000        # Documentos por batch
ELASTICSEARCH_SCROLL_TIMEOUT=5m       # Tiempo de vida del scroll
```

### Queries personalizadas

Crea archivos JSON en el directorio `queries/` con tu query de Elasticsearch:

```json
{
  "query": {
    "bool": {
      "must": [
        {"wildcard": {"message": "*Body:*"}},
        {"term": {"level": "ERROR"}}
      ],
      "filter": [
        {"range": {"@timestamp": {"gte": "2026-02-01", "lte": "2026-02-17"}}}
      ]
    }
  },
  "_source": ["message", "@timestamp", "level"]
}
```

Ver mÃ¡s ejemplos en [queries/README.md](queries/README.md).

### Encoding del archivo CSV

Si tu CSV tiene encoding especial, modifica en `extractor_csv.py`:

```python
with open(input_file, 'r', encoding='utf-8-sig') as csvfile:
```

### Frecuencia de progreso

Para cambiar cada cuÃ¡ntos registros se muestra el progreso, edita en `data_processor.py`:

```python
if registros_procesados % 1000 == 0:  # Cambiar 1000 por el valor deseado
```

## ğŸ› Troubleshooting

### Error: "Faltan variables de entorno requeridas"

**SoluciÃ³n:** AsegÃºrate de haber creado el archivo `.env` con las credenciales:
```bash
cp .env.example .env
# Edita .env con tus credenciales reales
```

### Error: SSL certificate verification failed

**SÃ­ntoma:** Error de certificado SSL al conectar a Elasticsearch

**Soluciones:**
1. Si es entorno de desarrollo con certificados autofirmados:
   ```env
   ELASTICSEARCH_VERIFY_SSL=false
   ```
2. Si es producciÃ³n, obtÃ©n el certificado correcto y configÃºralo

### Error: Authentication failed

**SÃ­ntoma:** Error 401 o mensaje de autenticaciÃ³n fallida

**SoluciÃ³n:** Verifica usuario y contraseÃ±a en `.env`:
```bash
python main.py test-connection  # Para probar credenciales
```

### Error: Index not found

**SÃ­ntoma:** Ãndice no encontrado o sin resultados

**SoluciÃ³n:**
1. Lista los Ã­ndices disponibles:
   ```bash
   python main.py test-connection
   ```
2. Ajusta el patrÃ³n en `.env`:
   ```env
   ELASTICSEARCH_INDEX=logs-2026.*
   ```

### Error: Request timeout

**SÃ­ntoma:** Timeout despuÃ©s de unos minutos

**SoluciÃ³n:** Aumenta el timeout en `.env`:
```env
ELASTICSEARCH_TIMEOUT=600  # 10 minutos
```

### Error: Too many results / Memory error

**SÃ­ntoma:** Se queda sin memoria con millones de registros

**Soluciones:**
1. Usa CSV intermedio en lugar de procesamiento directo
2. Divide por rangos de fechas pequeÃ±os
3. Reduce scroll_size:
   ```env
   ELASTICSEARCH_SCROLL_SIZE=500
   ```

### No se encuentra el .env

**SÃ­ntoma:** Variables de entorno no se cargan

**SoluciÃ³n:** El archivo `.env` debe estar en el mismo directorio donde ejecutas el script:
```bash
ls -la .env  # Verificar que existe
cat .env     # Verificar contenido (Â¡cuidado con la contraseÃ±a en pantalla!)
```

## ğŸ“ Casos de uso

Este extractor es ideal para:

- ğŸ“‹ **AnÃ¡lisis de logs de aplicaciones** - Extrae configuraciones desde logs de error
- ğŸ” **AuditorÃ­a de sistemas** - Identifica valores Ãºnicos en grandes volÃºmenes de logs
- ğŸ“Š **GeneraciÃ³n de datasets** - Prepara datos Ãºnicos para anÃ¡lisis o machine learning
- ğŸ§¹ **Limpieza de datos** - Normaliza y filtra informaciÃ³n de logs estructurados
- ğŸ“ˆ **Dashboards y reportes** - Exporta datos listos para visualizaciÃ³n
- ğŸ”„ **ETL de logs** - Transforma logs no estructurados en JSON estructurado
- ğŸš¨ **AnÃ¡lisis de incidentes** - Extrae rapidamente informaciÃ³n especÃ­fica de periodos de error

### Ejemplos prÃ¡cticos

#### 1. Analizar errores de la Ãºltima semana
```bash
python main.py elasticsearch --output-json errores_semana.json
# Query por defecto usa Ãºltimos 7 dÃ­as
```

#### 2. Extraer configuraciones de un dÃ­a especÃ­fico
```bash
# Crea queries/dia_especifico.json con el rango deseado
python main.py elasticsearch --query-file queries/dia_especifico.json --output-json configs.json
```

#### 3. Procesar CSV descargado manualmente de Kibana
```bash
python main.py csv --input export_kibana.csv --output datos.json
```

#### 4. Pipeline automatizado
```bash
# Descarga, procesa y guarda CSV para auditorÃ­a
python main.py elasticsearch \
  --output-csv backup_$(date +%Y%m%d).csv \
  --output-json datos_$(date +%Y%m%d).json
```

## ğŸ—ï¸ Arquitectura

```
ExtraerCSV/
â”œâ”€â”€ main.py                      # ğŸ¯ Punto de entrada CLI principal
â”œâ”€â”€ config.py                    # âš™ï¸ GestiÃ³n de configuraciÃ³n desde .env
â”œâ”€â”€ elasticsearch_client.py      # ğŸ”Œ Cliente para conectar a Elasticsearch
â”œâ”€â”€ data_processor.py            # ğŸ”„ LÃ³gica de procesamiento comÃºn
â”œâ”€â”€ extractor_csv.py             # ğŸ“„ Procesador especÃ­fico de CSV (legacy)
â”œâ”€â”€ requirements.txt             # ğŸ“¦ Dependencias Python
â”œâ”€â”€ .env.example                 # ğŸ“‹ Template de configuraciÃ³n
â”œâ”€â”€ .env                         # ğŸ”’ Credenciales (NO COMMITEAR)
â”œâ”€â”€ .gitignore                   # ğŸš« Archivos ignorados por git
â”œâ”€â”€ README.md                    # ğŸ“– Esta documentaciÃ³n
â”‚
â”œâ”€â”€ queries/                     # ğŸ“ Directorio de queries
â”‚   â”œâ”€â”€ README.md               # GuÃ­a de queries
â”‚   â”œâ”€â”€ default_query.json      # Query por defecto
â”‚   â””â”€â”€ error_logs_ejemplo.json # Ejemplo de query personalizada
â”‚
â””â”€â”€ datos_extraidos.json         # ğŸ“Š Archivo de salida generado
```

### Flujo de datos

#### Desde CSV local
```
CSV local â†’ extractor_csv.py â†’ data_processor.py â†’ JSON
```

#### Desde Elasticsearch (directo)
```
Elasticsearch â†’ elasticsearch_client.py â†’ data_processor.py â†’ JSON
```

#### Desde Elasticsearch (con CSV intermedio)
```
Elasticsearch â†’ elasticsearch_client.py â†’ CSV temporal â†’ data_processor.py â†’ JSON
```

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit de tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ï¿½ Troubleshooting

### Problema: No puedo conectar a Elasticsearch

**SÃ­ntomas:**
- Error 302 o redirecciÃ³n a `/login`
- Error 401 (Unauthorized)
- Error de certificado SSL

**Soluciones:**

ğŸ“– [Ver guÃ­a completa de troubleshooting â†’](TROUBLESHOOTING.md)

**VerificaciÃ³n rÃ¡pida:**
```bash
# Ejecutar script de depuraciÃ³n
python debug_es.py

# Probar conexiÃ³n manual
curl -k -u usuario:contraseÃ±a https://elasticsearch-host:puerto/
```

âš ï¸ **Nota importante**: Si Kibana estÃ¡ en frente de Elasticsearch (como proxy), 
necesitarÃ¡s contactar al administrador para:
- Exponer Elasticsearch en un endpoint sin Kibana
- O crear un API Key para acceso programÃ¡tico
- O configurar un bypass especÃ­fico

Ver [`TROUBLESHOOTING.md`](TROUBLESHOOTING.md) completo para todas las opciones.

## ï¿½ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## âœ‰ï¸ Contacto

Para preguntas, sugerencias o reportar problemas, por favor abre un issue en GitHub.

---

**Desarrollo:** 2026  
**VersiÃ³n:** 1.0.0
