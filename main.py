#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Extractor de Datos JSON desde CSV o Elasticsearch
Punto de entrada principal con interfaz CLI
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Any


def comando_csv(args):
    """Procesa archivo CSV local"""
    from extractor_csv import procesar_csv
    
    try:
        print("=" * 60)
        print("  PROCESADOR DE CSV LOCAL")
        print("=" * 60)
        print()
        
        stats = procesar_csv(args.input, args.output)
        
        print()
        print("=" * 60)
        print("  ‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
        print("=" * 60)
        print(f"  üìã Registros procesados: {stats['registros_procesados']:,}")
        print(f"  üìä Valores √∫nicos extra√≠dos: {stats['valores_unicos']}")
        if stats.get('registros_con_error', 0) > 0:
            print(f"  ‚ö†  Registros con errores: {stats['registros_con_error']:,}")
        print(f"  üìÅ Archivo de salida: {args.output}")
        print("=" * 60)
        
    except FileNotFoundError as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def comando_elasticsearch(args):
    """Descarga y procesa logs desde Elasticsearch"""
    from config import load_config
    from elasticsearch_client import ElasticsearchClient
    from data_processor import procesar_registros_iterable
    
    try:
        print("=" * 60)
        print("  EXTRACTOR DESDE ELASTICSEARCH")
        print("=" * 60)
        print()
        
        # Cargar configuraci√≥n
        print("‚öôÔ∏è  Cargando configuraci√≥n...")
        config = load_config()
        print(f"‚úì Configuraci√≥n cargada: {config.es_host}")
        
        # Cargar query
        query_dict = cargar_query(args.query_file)
        
        # Mostrar query si est√° en modo verbose
        if args.verbose:
            print("\nüìã Query a ejecutar:")
            print(json.dumps(query_dict, indent=2))
            print()
        
        # Conectar a Elasticsearch
        print("üîå Conectando a Elasticsearch...")
        client = ElasticsearchClient(config)
        
        # Test de conexi√≥n
        info = client.test_connection()
        print(f"‚úÖ Conectado a: {info['cluster_name']} (v{info['version']})")
        
        # Obtener estimaci√≥n de documentos
        index = args.index or config.es_index
        print(f"üìä √çndice: {index}")
        
        total_est = client.get_total_estimate(query_dict, index)
        if total_est > 0:
            print(f"üìä Documentos estimados: {total_est:,}")
        
        print()
        
        # Decisi√≥n: CSV intermedio o directo a JSON
        if args.output_csv:
            # Opci√≥n A: Descargar a CSV, luego procesar
            print(f"üì• Descargando a CSV intermedio: {args.output_csv}")
            count = client.download_to_csv(query_dict, args.output_csv, index_pattern=index)
            
            if count == 0:
                print("‚ö†Ô∏è  No se encontraron documentos que coincidan con la query")
                return
            
            # Procesar el CSV descargado
            print(f"\nüìä Procesando CSV a JSON: {args.output_json}")
            from extractor_csv import procesar_csv
            stats = procesar_csv(args.output_csv, args.output_json)
            
        else:
            # Opci√≥n B: Procesamiento directo sin CSV intermedio
            print("üì• Descargando y procesando directamente a JSON...")
            docs_generator = client.get_documents_generator(query_dict, index)
            stats = procesar_registros_iterable(docs_generator, args.output_json, show_progress=True)
        
        # Resumen final
        print()
        print("=" * 60)
        print("  ‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
        print("=" * 60)
        print(f"  üìã Registros procesados: {stats['registros_procesados']:,}")
        print(f"  üìä Registros con valores: {stats.get('registros_con_valores', 'N/A'):,}")
        print(f"  üìä Valores √∫nicos extra√≠dos: {stats['valores_unicos']}")
        print(f"  üìÅ Archivo de salida JSON: {args.output_json}")
        if args.output_csv:
            print(f"  üìÅ Archivo CSV intermedio: {args.output_csv}")
        print("=" * 60)
        
    except ValueError as e:
        print(f"\n{e}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def comando_test_connection(args):
    """Prueba la conexi√≥n con Elasticsearch"""
    from config import load_config
    from elasticsearch_client import ElasticsearchClient
    
    try:
        print("=" * 60)
        print("  TEST DE CONEXI√ìN ELASTICSEARCH")
        print("=" * 60)
        print()
        
        # Cargar configuraci√≥n
        print("‚öôÔ∏è  Cargando configuraci√≥n...")
        config = load_config()
        
        print(f"üìã Host: {config.es_host}")
        print(f"üìã Usuario: {config.es_user}")
        print(f"üìã √çndice: {config.es_index}")
        print(f"üìã SSL Verify: {config.verify_ssl}")
        print()
        
        # Conectar
        print("üîå Probando conexi√≥n...")
        client = ElasticsearchClient(config)
        info = client.test_connection()
        
        print("‚úÖ ¬°Conexi√≥n exitosa!")
        print()
        print(f"  Cluster: {info['cluster_name']}")
        print(f"  Versi√≥n: {info['version']}")
        print(f"  Host: {info['host']}")
        print()
        
        # Listar √≠ndices disponibles
        print(f"üìä √çndices disponibles con patr√≥n '{config.es_index}':")
        indices = client.get_available_indices(config.es_index)
        
        if indices:
            for idx in indices[:10]:
                print(f"  ‚úì {idx}")
            if len(indices) > 10:
                print(f"  ... y {len(indices) - 10} √≠ndices m√°s")
        else:
            print("  ‚ö†Ô∏è  No se encontraron √≠ndices con ese patr√≥n")
        
        print()
        print("=" * 60)
        
    except ValueError as e:
        print(f"\n{e}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)


def cargar_query(query_file: str = None) -> Dict[str, Any]:
    """
    Carga query desde archivo JSON o retorna query por defecto
    
    Args:
        query_file: Ruta al archivo JSON con la query (opcional)
        
    Returns:
        dict: Query de Elasticsearch
    """
    if query_file:
        query_path = Path(query_file)
        if not query_path.exists():
            raise FileNotFoundError(f"Archivo de query no encontrado: {query_file}")
        
        with open(query_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        # Query por defecto: √∫ltimos 7 d√≠as, mensajes con "Body"
        return {
            "query": {
                "bool": {
                    "must": [
                        {"wildcard": {"message": "*Body:*"}},
                        {"exists": {"field": "message"}}
                    ],
                    "filter": [
                        {"range": {"@timestamp": {"gte": "now-7d"}}}
                    ]
                }
            },
            "_source": ["message", "@timestamp"]
        }


def main():
    """Funci√≥n principal con argumentos CLI"""
    parser = argparse.ArgumentParser(
        description='Extractor de datos JSON desde CSV o Elasticsearch',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:

  # Procesar CSV local
  python main.py csv --input datos.csv --output salida.json

  # Descargar desde Elasticsearch directamente a JSON
  python main.py elasticsearch --output-json salida.json

  # Descargar desde Elasticsearch con CSV intermedio
  python main.py elasticsearch --output-csv logs.csv --output-json salida.json

  # Usar query personalizada
  python main.py elasticsearch --query-file queries/custom.json --output-json salida.json

  # Probar conexi√≥n
  python main.py test-connection
        """
    )
    
    subparsers = parser.add_subparsers(dest='comando', help='Comando a ejecutar')
    subparsers.required = True
    
    # Subcomando: csv
    parser_csv = subparsers.add_parser('csv', help='Procesar archivo CSV local')
    parser_csv.add_argument('--input', '-i', required=True, 
                           help='Archivo CSV de entrada')
    parser_csv.add_argument('--output', '-o', required=True,
                           help='Archivo JSON de salida')
    parser_csv.set_defaults(func=comando_csv)
    
    # Subcomando: elasticsearch
    parser_es = subparsers.add_parser('elasticsearch', help='Descargar desde Elasticsearch')
    parser_es.add_argument('--query-file', '-q',
                          help='Archivo JSON con query personalizada (opcional)')
    parser_es.add_argument('--output-json', '-o', required=True,
                          help='Archivo JSON de salida')
    parser_es.add_argument('--output-csv', '-c',
                          help='Guardar CSV intermedio (opcional)')
    parser_es.add_argument('--index', '-idx',
                          help='Patr√≥n de √≠ndices (override de .env)')
    parser_es.add_argument('--verbose', '-v', action='store_true',
                          help='Mostrar query y detalles adicionales')
    parser_es.set_defaults(func=comando_elasticsearch)
    
    # Subcomando: test-connection
    parser_test = subparsers.add_parser('test-connection', help='Probar conexi√≥n con Elasticsearch')
    parser_test.set_defaults(func=comando_test_connection)
    
    # Parsear argumentos y ejecutar comando
    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()
